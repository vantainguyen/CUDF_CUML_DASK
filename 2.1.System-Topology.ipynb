{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e82476d",
   "metadata": {},
   "source": [
    "\n",
    "<p> <center> <a href=\"../Start_Here.ipynb\">Home Page</a> </center> </p>\n",
    "\n",
    " \n",
    "<div>\n",
    "    <span style=\"float: left; width: 33%; text-align: left;\"><a href=\"1.Introduction-to-Distributed-Deep-Learning.ipynb\">Previous Notebook</a></span>\n",
    "    <span style=\"float: left; width: 33%; text-align: center;\">\n",
    "        <a href=\"1.Introduction-to-Distributed-Deep-Learning.ipynb\">1</a>\n",
    "        <a >2</a>\n",
    "        <a href=\"3.Hands-on-Multi-GPU.ipynb\">3</a>\n",
    "        <a href=\"4.Convergence.ipynb\">4</a>\n",
    "    </span>\n",
    "    <span style=\"float: left; width: 33%; text-align: right;\"><a href=\"3.Hands-on-Multi-GPU.ipynb\">Next Notebook</a></span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea172b",
   "metadata": {},
   "source": [
    "# Introduction to Distributed Deep Learning - Part 2\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "- [Understanding System Topology](#Understanding-System-Topology)\n",
    "    - [Communication concepts](#Communication-concepts)\n",
    "- [Intra-Node Communication Topology](#Intra-Node-communication-Topology)\n",
    "    - [Performance variation due to system topology](#Performance-variation-due-to-system-topology)\n",
    "- [NCCL](#NCCL)\n",
    "    - [NCCL_P2P_LEVEL=0 or P2P Disabled](#NCCL_P2P_LEVEL=0-or-P2P-Disabled)\n",
    "    - [NCCL_P2P_LEVEL=1 or P2P via PCIe](#NCCL_P2P_LEVEL=1-or-P2P-via-PCIe)\n",
    "- [Benchmarking the system topology](#Benchmarking-the-system-topology)\n",
    "\n",
    "**The objectives of this Notebook is to make you understand:**\n",
    "\n",
    "- How system topolgy plays a role in Distributed training.\n",
    "- Intra-node topology and underlying technologies like P2P and their implication on program performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b543f7a",
   "metadata": {},
   "source": [
    "# Understanding System Topology\n",
    "\n",
    "In our previous notebook when we calculated the `throughput` of deep learning training with different parameters, we saw a slight dip when we scaled from 4 to 8 GPUs. Let us try to reason it by understanding the underlying system.\n",
    "\n",
    "Before we begin, let us define two important terms:\n",
    "\n",
    "* **Latency:** The amount of time it takes to take a unit of data from point A to point B. For example, if 4bytes of data can be transferred from point A to B in 4 $\\mu$s, that is the latency of transfer.\n",
    "* **Bandwidth:** The amount of data that can be transferred from point A to point B in a unit of time. For example, if the width of the bus is 64KiB and latency of transfer between point A and B is 4 $\\mu$s, the bandwidth is 64KiB * (1/4$\\mu$s) = 1.6 GiB/s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa346e5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Communication concepts\n",
    "\n",
    "There are many ways in which GPUs can transfer data between one another , let us look at two of the most used copy operations. Understanding these will help us with the further sections of the notebook when we benchmark and toggle different options available to us.\n",
    "\n",
    "#### Host Staging of Copy Operations\n",
    "\n",
    "The path taken by the data in both the cases is denoted by the red arrow as follows:\n",
    "\n",
    "<center><img src=\"images/memcpy_host_staging.png\"/></center>\n",
    "\n",
    "That is, in the above GPU-to-GPU memory copy, the data traverses from GPU 0 the PCIe bus to the CPU, where it is staged in a buffer before being copied to GPU 1. This is called \"host staging\" and it decreases the bandwidth while increasing the latency of the operation. If we eliminate host staging, we can usually improve the performance of our application.\n",
    "\n",
    "#### Peer-to-Peer Memory Access\n",
    "\n",
    "P2P allows devices to address each other's memory from within device kernels and eliminates host staging by transferring data either through the PCIe switch or through NVLink as denoted by the red arrow below. \n",
    "\n",
    "<center><img src=\"images/memcpy_p2p_overview.png\"/></center>\n",
    "\n",
    "Peer-to-Peer (P2P) memory access requires GPUs to share a Unified Virtual Address Space (UVA). UVA means that a single address space is used for the host and all modern NVIDIA GPU devices (specifically, those with compute capibility of 2.0 or higher).\n",
    "\n",
    "Let us now try to understand the Intra-node topology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33313ee",
   "metadata": {},
   "source": [
    "## Intra-Node communication Topology\n",
    "\n",
    "Run the command below to display your node's GPU and NIC communication topology:\n",
    "\n",
    "### DGX-1 (V100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c770dd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi topo -m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c33e5e5",
   "metadata": {},
   "source": [
    "Output of running the command: \n",
    "\n",
    "![nvidia_smi_topo_output](images/nvidia_smi_topo_output.png)\n",
    "\n",
    "Focus on a particular row, say GPU 0. The output states that GPUs 1 through 4 are connected to it via NVLink (in addition to PCIe) and GPUs 5 through 7 are connected to it via PCIe as well as an \"SMP\" interconnect. We have a dual-socket system and the CPUs in these sockets are connected by an interconnect known as SMP interconnect.\n",
    "\n",
    "Thus, GPU 0 to GPU 5 communication happens via not just PCIe, but also over the inter-socket interconnect within the same node. Clearly, this is a longer path than say the one between GPU 0 and GPU 1, which are connected via NVLink directly.\n",
    "\n",
    "Even within the GPUs connected via NVLink, we see different annotations such as `NV1` and `NV2` that affect the communication bandwidth and hence the performance. In this section, we will explore the nuances associated with a diverse intra-node GPU communication topology like in the output above. Specifically, in our system, the communication topology is as follows:\n",
    "\n",
    "![dgx1_8x_tesla_v100_topo](images/dgx1_8x_tesla_v100_topo.png)\n",
    "\n",
    "\n",
    "### DGX-1 (A100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80735615-5681-47fb-8199-453f66a4f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGULARITY_RUN=\"singularity run --nv --env TF_CPP_MIN_LOG_LEVEL=3 ~/DDL.simg \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9a2219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "NVIDIA A100-SXM4-80GB\n",
      "NVIDIA A100-SXM4-80GB\n",
      "NVIDIA A100-SXM4-80GB\n",
      "NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "#run this cell to see the topology of A100\n",
    "COMMAND = SINGULARITY_RUN + 'nvidia-smi --query-gpu=gpu_name --format=csv 2> /dev/null' #' nvidia-smi topo -m 2> /dev/null' \n",
    "!echo  $COMMAND > command && srun --partition=gpu -n1 --gres=gpu:4 /bin/bash ./command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f443156e",
   "metadata": {},
   "source": [
    "In constrast to V100, GPU0 to GPU7 are connected via NVLink(NV12) and in summary, each GPU in A100 is connected to all other GPUs via the third generation NVLink. As a result, this doubles the GPU-to-GPU direct bandwidth to 600 gigabytes per second (GB/s), almost 10X higher than PCIe Gen 4.\n",
    "\n",
    "<br/>\n",
    "<center><img src=\"images/DGX-A100-Topology.jpg\" width=\"70%\" height=\"70%\"/></center\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5eeba6",
   "metadata": {},
   "source": [
    "### Overview \n",
    "\n",
    "Qualitatively, the bandwidth and latency vary with the topology as follows:\n",
    "\n",
    "<br/>\n",
    "<center><img src=\"images/intra_node_topology_map.png\"/></center>\n",
    "\n",
    "Host staging implies traversing through the CPU and the travel path taken is one of PHB, NODE, and SYS. In contrast, if the path taken is either NV1, NV2, or PIX, then P2P is available. PXB implies that the GPUs belong to different PCIe hubs and P2P is usually not supported in this case.\n",
    "\n",
    "A double NVLink connection provides twice the bandwidth compared to a single NVLink. \n",
    "\n",
    "For a pair of 2 GPUs, the peak bidirectional bandwidth are as follows:\n",
    "* PCIe: Using PIX topology, 15.75GB/s for PCIe Gen 3.0 and 31.5GB/s for PCIe Gen 4.0.\n",
    "* NVLink: Using NV# topology, 50GB/s per connection. So a double NVLink connection has 100GB/s peak bidirectional bandwidth.\n",
    "\n",
    "Let us understand what difference the underlying communication topology can make to the application performance in the following sub-section.\n",
    "\n",
    "**Note:** If your command output doesn't show any NVLink connection or if there's no difference in connection type (PIX, PXB, PHB, NODE, SYS, NV#) between any 2 pair of GPUs, then the communication bandwidth and latency will likely be the same between any pair and the following sub-sections will not display any performance difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9808b3",
   "metadata": {},
   "source": [
    "# NCCL\n",
    "\n",
    "The NVIDIA Collective Communication Library (NCCL) implements multi-GPU and multi-node communication primitives optimized for NVIDIA GPUs and Networking. NCCL provides routines such as `all-gather`, `all-reduce`, `broadcast`, `reduce`, `reduce-scatter` as well as point-to-point send and receive that are optimized to achieve high bandwidth and low latency over PCIe and NVLink high-speed interconnects within a node and over NVIDIA Mellanox Network across nodes.\n",
    "\n",
    "The Horovod framework also uses NCCL Collective communications to keep the all the GPUs in sync , we can then toggle P2P levels using Environment variables to manually switch between different communication protocols available. The complete list of Environment variables can be found \n",
    "[here](https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/env.html#nccl-p2p-disable)\n",
    "\n",
    "Let us now toggle Peer-to-peer levels using the `NCCL_P2P_LEVEL` environment variable. \n",
    "\n",
    "```text\n",
    "NCCL_P2P_LEVEL\n",
    "(since 2.3.4)\n",
    "\n",
    "The NCCL_P2P_LEVEL variable allows the user to finely control when to use the peer to peer (P2P) transport between GPUs. The level defines the maximum distance between GPUs where NCCL will use the P2P transport.\n",
    "\n",
    "Values accepted\n",
    "LOC or 0 : Never use P2P (always disabled)\n",
    "\n",
    "NVL : Use P2P when GPUs are connected through NVLink\n",
    "\n",
    "PIX or 1 : Use P2P when GPUs are on the same PCI switch.\n",
    "\n",
    "PXB or 2 : Use P2P when GPUs are connected through PCI switches (potentially multiple hops).\n",
    "\n",
    "PHB or 3, or 4 : Use P2P when GPUs are on the same NUMA node. Traffic will go through the CPU.\n",
    "\n",
    "SYS or 5 : Use P2P betweem NUMA nodes, potentially crossing the SMP interconnect (e.g. QPI/UPI).\n",
    "```\n",
    "\n",
    "We have benchmarked for the case where we use NVLink and verified it through `NCCL_DEBUG` environment variable, let us now try two different settings and compare their throughputs.\n",
    "\n",
    "### NCCL_P2P_LEVEL=0 or P2P Disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d58b35-deea-4b85-b077-a9c5f1c15ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGULARITY_RUN=\"singularity run --nv --env TF_CPP_MIN_LOG_LEVEL=3 --env NCCL_P2P_LEVEL=0 --env NCCL_DEBUG=INFO ~/DDL.simg \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9571de9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,0]<stdout>:Epoch 1/6\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO Bootstrap : Using lo:127.0.0.1<0>\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO P2P plugin IBext\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_6:1/IB/SHARP [6]mlx5_7:1/IB/SHARP [7]mlx5_8:1/IB/SHARP [8]mlx5_9:1/IB/SHARP [9]mlx5_10:1/IB/SHARP [10]mlx5_11:1/RoCE ; OOB lo:127.0.0.1<0>\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO Using network IBext\n",
      "[1,0]<stdout>:NCCL version 2.10.3+cuda11.4\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO Bootstrap : Using lo:127.0.0.1<0>\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO P2P plugin IBext\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_6:1/IB/SHARP [6]mlx5_7:1/IB/SHARP [7]mlx5_8:1/IB/SHARP [8]mlx5_9:1/IB/SHARP [9]mlx5_10:1/IB/SHARP [10]mlx5_11:1/RoCE ; OOB lo:127.0.0.1<0>\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO Using network IBext\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO Channel 00/02 :    0   1\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO Channel 01/02 :    0   1\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO Channel 00 : 1[f000] -> 0[7000] via direct shared memory\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO Channel 01 : 1[f000] -> 0[7000] via direct shared memory\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO Channel 00 : 0[7000] -> 1[f000] via direct shared memory\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO Channel 01 : 0[7000] -> 1[f000] via direct shared memory\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO Connected all rings\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO Connected all trees\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO Connected all rings\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO Connected all trees\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[1,1]<stdout>:dgx02:2338461:2338483 [1] NCCL INFO comm 0x7fac906edf80 rank 1 nranks 2 cudaDev 1 busId f000 - Init COMPLETE\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO comm 0x7f46346eebd0 rank 0 nranks 2 cudaDev 0 busId 7000 - Init COMPLETE\n",
      "[1,0]<stdout>:dgx02:2338460:2338482 [0] NCCL INFO Launch mode Parallel\n",
      "[1,0]<stdout>:58/58 - 17s - loss: 0.5741 - accuracy: 0.8247\n",
      "[1,0]<stdout>:Epoch time : 17.44037890434265\n",
      "[1,0]<stdout>:Images/sec: 3440.29\n",
      "[1,0]<stdout>:Epoch 2/6\n",
      "[1,0]<stdout>:58/58 - 1s - loss: 0.1681 - accuracy: 0.9505\n",
      "[1,0]<stdout>:Epoch time : 0.6812644004821777\n",
      "[1,0]<stdout>:Images/sec: 88071.53\n",
      "[1,0]<stdout>:Epoch 3/6\n",
      "[1,0]<stdout>:58/58 - 1s - loss: 0.1061 - accuracy: 0.9688\n",
      "[1,0]<stdout>:Epoch time : 0.675795316696167\n",
      "[1,0]<stdout>:Images/sec: 88784.28\n",
      "[1,0]<stdout>:Epoch 4/6\n",
      "[1,0]<stdout>:58/58 - 1s - loss: 0.0845 - accuracy: 0.9750\n",
      "[1,0]<stdout>:Epoch time : 0.69940185546875\n",
      "[1,0]<stdout>:Images/sec: 85787.59\n",
      "[1,0]<stdout>:Epoch 5/6\n",
      "[1,0]<stdout>:58/58 - 1s - loss: 0.0734 - accuracy: 0.9785\n",
      "[1,0]<stdout>:Epoch time : 0.6997776031494141\n",
      "[1,0]<stdout>:Images/sec: 85741.53\n",
      "[1,0]<stdout>:Epoch 6/6\n",
      "[1,0]<stdout>:58/58 - 1s - loss: 0.0639 - accuracy: 0.9799\n",
      "[1,0]<stdout>:Epoch time : 0.6317968368530273\n",
      "[1,0]<stdout>:Images/sec: 94967.24\n",
      "[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/horovod/_keras/callbacks.py:58: UserWarning: Some callbacks may not have access to the averaged metrics, see https://github.com/horovod/horovod/issues/2440\n",
      "[1,0]<stderr>:  warnings.warn(\n",
      "[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/horovod/_keras/callbacks.py:58: UserWarning: Some callbacks may not have access to the averaged metrics, see https://github.com/horovod/horovod/issues/2440\n",
      "[1,1]<stderr>:  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "COMMAND = SINGULARITY_RUN + ' horovodrun -np 2 --mpi-args=\"--oversubscribe\" python3 ../source_code/N2/cnn_fmnist.py --batch-size=512 2> /dev/null' \n",
    "!echo  $COMMAND > command && srun --partition=gpu -n1 --gres=gpu:2 /bin/bash ./command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07df4a",
   "metadata": {},
   "source": [
    "**Output of running the command on DGX-1 V100** : \n",
    "\n",
    "```bash\n",
    "NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\n",
    "NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0\n",
    "NCCL INFO Channel 00/02 :    0   1\n",
    "NCCL INFO Setting affinity for GPU 3 to 0fffff00,000fffff\n",
    "NCCL INFO Channel 01/02 :    0   1\n",
    "NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1\n",
    "NCCL INFO Setting affinity for GPU 0 to 0fffff00,000fffff\n",
    "NCCL INFO Channel 00 : 1[b000] -> 0[6000] via direct shared memory\n",
    "NCCL INFO Channel 00 : 0[6000] -> 1[b000] via direct shared memory\n",
    "NCCL INFO Channel 01 : 1[b000] -> 0[6000] via direct shared memory\n",
    "NCCL INFO Channel 01 : 0[6000] -> 1[b000] via direct shared memory\n",
    "NCCL INFO Connected all rings\n",
    "NCCL INFO Connected all trees\n",
    "NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512\n",
    "NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
    "\n",
    "Epoch 4/8\n",
    "Images/sec: 95033.4\n",
    "Epoch 5/8\n",
    "Images/sec: 94848.44\n",
    "Epoch 6/8\n",
    "Images/sec: 94289.97\n",
    "```\n",
    "\n",
    "**Output of running the command on DGX-1 A100** :\n",
    "\n",
    "```bash\n",
    "NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\n",
    "NCCL INFO PXN Disabled as plugin is v4\n",
    "NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\n",
    "NCCL INFO PXN Disabled as plugin is v4\n",
    "NCCL INFO Channel 00/04 :    0   1\n",
    "NCCL INFO Channel 01/04 :    0   1\n",
    "NCCL INFO Trees [0] -1/-1/-1->1->0 [1] 0/-1/-1->1->-1 [2] -1/-1/-1->1->0 [3] 0/-1/-1->1->-1\n",
    "NCCL INFO Channel 02/04 :    0   1\n",
    "NCCL INFO Channel 03/04 :    0   1\n",
    "NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1 [2] 1/-1/-1->0->-1 [3] -1/-1/-1->0->1\n",
    "NCCL INFO Channel 00 : 1[4e000] -> 0[7000] via direct shared memory\n",
    "NCCL INFO Channel 01 : 1[4e000] -> 0[7000] via direct shared memory\n",
    "NCCL INFO Channel 00 : 0[7000] -> 1[4e000] via direct shared memory\n",
    "NCCL INFO Channel 02 : 1[4e000] -> 0[7000] via direct shared memory\n",
    "NCCL INFO Channel 01 : 0[7000] -> 1[4e000] via direct shared memory\n",
    "NCCL INFO Channel 03 : 1[4e000] -> 0[7000] via direct shared memory\n",
    "NCCL INFO Channel 02 : 0[7000] -> 1[4e000] via direct shared memory\n",
    "NCCL INFO Channel 03 : 0[7000] -> 1[4e000] via direct shared memory\n",
    "NCCL INFO Connected all rings\n",
    "NCCL INFO Connected all trees\n",
    "NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/512\n",
    "NCCL INFO 4 coll channels, 4 p2p channels, 2 p2p channels per peer\n",
    "\n",
    "\n",
    "Epoch 4/6\n",
    "Images/sec: 98121.52\n",
    "Epoch 5/6\n",
    "Images/sec: 97400.23\n",
    "Epoch 6/6\n",
    "Images/sec: 97135.72\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac3702",
   "metadata": {},
   "source": [
    "### NCCL_P2P_LEVEL=1 or P2P via PCIe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c9166-b9b4-41db-b6bb-9544d65c11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGULARITY_RUN=\"singularity run --nv --env TF_CPP_MIN_LOG_LEVEL=3 --env NCCL_P2P_LEVEL=1 --env NCCL_DEBUG=INFO ~/DDL.simg \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMAND = SINGULARITY_RUN + ' horovodrun -np 2 --mpi-args=\"--oversubscribe\" python3 ../source_code/N2/cnn_fmnist.py --batch-size=512 2> /dev/null' \n",
    "!echo  $COMMAND > command && srun --partition=gpu -n1 --gres=gpu:2 /bin/bash ./command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893cb1f6",
   "metadata": {},
   "source": [
    "**Output of running the command on DGX-1 V100**: \n",
    "\n",
    "```bash\n",
    "NCCL INFO NCCL_P2P_LEVEL set by environment to PIX\n",
    "NCCL INFO NCCL_P2P_LEVEL set by environment to PIX\n",
    "NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0\n",
    "NCCL INFO Channel 00/04 :    0   1\n",
    "NCCL INFO Channel 01/04 :    0   1\n",
    "NCCL INFO Channel 02/04 :    0   1\n",
    "NCCL INFO Setting affinity for GPU 3 to 0fffff00,000fffff\n",
    "NCCL INFO Channel 03/04 :    0   1\n",
    "NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1\n",
    "NCCL INFO Setting affinity for GPU 0 to 0fffff00,000fffff\n",
    "NCCL INFO Channel 00 : 1[b000] -> 0[6000] via P2P/IPC\n",
    "NCCL INFO Channel 00 : 0[6000] -> 1[b000] via P2P/IPC\n",
    "NCCL INFO Channel 01 : 1[b000] -> 0[6000] via P2P/IPC\n",
    "NCCL INFO Channel 01 : 0[6000] -> 1[b000] via P2P/IPC\n",
    "NCCL INFO Channel 02 : 1[b000] -> 0[6000] via P2P/IPC\n",
    "NCCL INFO Channel 02 : 0[6000] -> 1[b000] via P2P/IPC\n",
    "NCCL INFO Channel 03 : 1[b000] -> 0[6000] via P2P/IPC\n",
    "NCCL INFO Channel 03 : 0[6000] -> 1[b000] via P2P/IPC\n",
    "NCCL INFO Connected all rings\n",
    "NCCL INFO Connected all trees\n",
    "Epoch 4/8\n",
    "Images/sec: 96529.63\n",
    "Epoch 5/8\n",
    "Images/sec: 97288.7\n",
    "Epoch 6/8\n",
    "Images/sec: 97230.33\n",
    "Epoch 7/8\n",
    "Images/sec: 97701.72\n",
    "Epoch 8/8\n",
    "Images/sec: 97075.39\n",
    "```\n",
    "\n",
    "**Output of running the command on DGX-1 A100**:\n",
    "\n",
    "```bash\n",
    "NCCL INFO NCCL_P2P_LEVEL set by environment to PIX\n",
    "NCCL INFO PXN Disabled as plugin is v4\n",
    "NCCL INFO NCCL_P2P_LEVEL set by environment to PIX\n",
    "NCCL INFO PXN Disabled as plugin is v4\n",
    "NCCL INFO Channel 00/24 :    0   1\n",
    "NCCL INFO Channel 01/24 :    0   1\n",
    "NCCL INFO Channel 02/24 :    0   1\n",
    "NCCL INFO Channel 03/24 :    0   1\n",
    "NCCL INFO Channel 04/24 :    0   1\n",
    "NCCL INFO Channel 05/24 :    0   1\n",
    "NCCL INFO Channel 06/24 :    0   1\n",
    "NCCL INFO Channel 07/24 :    0   1\n",
    "NCCL INFO Channel 08/24 :    0   1\n",
    "NCCL INFO Channel 09/24 :    0   1\n",
    "NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0 [8] -1/-1/-1->1->0 [9] -1/-1/-1->1->0 [10] -1/-1/-1->1->0 [11] -1/-1/-1->1->0 [12] -1/-1/-1->1->0 [13] -1/-1/-1->1->0 [14] -1/-1/-1->1->0 [15] -1/-1/-1->1->0 [16] -1/-1/-1->1->0 [17] -1/-1/-1->1->0 [18] -1/-1/-1->1->0 [19] -1/-1/-1->1->0 [20] -1/-1/-1->1->0 [21] -1/-1/-1->1->0 [22] -1/-1/-1->1->0 [23] -1/-1/-1->1->0\n",
    "[0] NCCL INFO Channel 10/24 :    0   1\n",
    "NCCL INFO Channel 11/24 :    0   1\n",
    "-------------------------\n",
    "NCCL INFO Channel 23/24 :    0   1\n",
    "NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1\n",
    "NCCL INFO Channel 00 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 00 : 0[7000] -> 1[4e000] via P2P/IPC/read\n",
    "NCCL INFO Channel 01 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 02 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 03 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 04 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 05 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 06 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 07 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 08 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 09 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 10 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "------------------------\n",
    "NCCL INFO Channel 21 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 22 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 23 : 1[4e000] -> 0[7000] via P2P/IPC/read\n",
    "NCCL INFO Channel 04 : 0[7000] -> 1[4e000] via P2P/IPC/read\n",
    "NCCL INFO Channel 05 : 0[7000] -> 1[4e000] via P2P/IPC/read\n",
    "------------------------\n",
    "NCCL INFO Channel 22 : 0[7000] -> 1[4e000] via P2P/IPC/read\n",
    "NCCL INFO Channel 23 : 0[7000] -> 1[4e000] via P2P/IPC/read\n",
    "NCCL INFO Connected all rings\n",
    "NCCL INFO Connected all trees\n",
    "\n",
    "Epoch 4/6\n",
    "Images/sec: 105595.09\n",
    "Epoch 5/6\n",
    "Images/sec: 102635.29\n",
    "Epoch 6/6\n",
    "Images/sec: 104972.76\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63824c90",
   "metadata": {},
   "source": [
    "We can summarise the results using the following table. \n",
    "\n",
    "|GPUs|Condition|Throughput V100|Throughput A100|\n",
    "|-|-|-|-|\n",
    "|0,3|P2P via NVLink|~100000|~166697 (batch-size=8192)|\n",
    "|0,3|P2P via PCIe|~97000| ~104000|\n",
    "|0,3|P2P Disabled|~95000|~97000 |\n",
    "\n",
    "We now understood the role of communication and hardware configuration for training. In our case, we used a smaller model for quicker runtimes. The decrease in throughput due to communication is more pronounced when the data transfer size increases for larger models that typically require multi-node training. In such cases, NVLink helps reduce the scaling efficiency gap as we scale further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67065b6f",
   "metadata": {},
   "source": [
    "### Benchmarking the system topology\n",
    "\n",
    "The above application is not highly memory intensive as we mentioned earlier. Therefore, to get a quantitative measure of latency and bandwidth impact due to topology, we run a micro-benchmark.\n",
    "\n",
    "**The p2pBandwidthLatencyTest micro-benchmark**\n",
    "\n",
    "p2pBandwidthLatencyTest is a part of [CUDA Samples GitHub repository](https://github.com/NVIDIA/cuda-samples) available to help CUDA developers. \n",
    "\n",
    "As the name suggests, this test measures the bandwidth and latency impact of P2P and underlying communication topology. Let's compile the benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d7255e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f p2pBandwidthLatencyTest p2pBandwidthLatencyTest.o\n",
      "rm -rf ../../bin/x86_64/linux/release/p2pBandwidthLatencyTest\n",
      "/usr/local/cuda/bin/nvcc -ccbin g++ -I../../Common -I../source_code/N2/Common  -m64    -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o p2pBandwidthLatencyTest.o -c p2pBandwidthLatencyTest.cu\n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "/usr/local/cuda/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o p2pBandwidthLatencyTest p2pBandwidthLatencyTest.o \n",
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "mkdir -p ../../bin/x86_64/linux/release\n",
      "cp p2pBandwidthLatencyTest ../../bin/x86_64/linux/release\n"
     ]
    }
   ],
   "source": [
    "COMMAND = SINGULARITY_RUN + ' make clean \\&\\& make 2> /dev/null'\n",
    "!echo $COMMAND > command && srun --partition=gpu -n1 --gres=gpu:1 /bin/bash ./command\n",
    "#!cd ../source_code/N2/Samples/p2pBandwidthLatencyTest/ && make clean && make"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb509a",
   "metadata": {},
   "source": [
    "Now, let's run the benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc69bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[P2P (Peer-to-Peer) GPU Bandwidth Latency Test]\n",
      "Device: 0, NVIDIA A100-SXM4-80GB, pciBusID: 7, pciDeviceID: 0, pciDomainID:0\n",
      "Device: 1, NVIDIA A100-SXM4-80GB, pciBusID: f, pciDeviceID: 0, pciDomainID:0\n",
      "Device: 2, NVIDIA A100-SXM4-80GB, pciBusID: 47, pciDeviceID: 0, pciDomainID:0\n",
      "Device: 3, NVIDIA A100-SXM4-80GB, pciBusID: 4e, pciDeviceID: 0, pciDomainID:0\n",
      "Device=0 CAN Access Peer Device=1\n",
      "Device=0 CAN Access Peer Device=2\n",
      "Device=0 CAN Access Peer Device=3\n",
      "Device=1 CAN Access Peer Device=0\n",
      "Device=1 CAN Access Peer Device=2\n",
      "Device=1 CAN Access Peer Device=3\n",
      "Device=2 CAN Access Peer Device=0\n",
      "Device=2 CAN Access Peer Device=1\n",
      "Device=2 CAN Access Peer Device=3\n",
      "Device=3 CAN Access Peer Device=0\n",
      "Device=3 CAN Access Peer Device=1\n",
      "Device=3 CAN Access Peer Device=2\n",
      "\n",
      "***NOTE: In case a device doesn't have P2P access to other one, it falls back to normal memcopy procedure.\n",
      "So you can see lesser Bandwidth (GB/s) and unstable Latency (us) in those cases.\n",
      "\n",
      "P2P Connectivity Matrix\n",
      "     D\\D     0     1     2     3\n",
      "     0\t     1     1     1     1\n",
      "     1\t     1     1     1     1\n",
      "     2\t     1     1     1     1\n",
      "     3\t     1     1     1     1\n",
      "Unidirectional P2P=Disabled Bandwidth Matrix (GB/s)\n",
      "   D\\D     0      1      2      3 \n",
      "     0 1573.51   8.06   9.09   8.92 \n",
      "     1   8.12 1575.10   9.45   9.05 \n",
      "     2   9.09   9.06 1565.63   8.05 \n",
      "     3   9.52   8.94   8.32 1557.83 \n",
      "Unidirectional P2P=Enabled Bandwidth (P2P Writes) Matrix (GB/s)\n",
      "   D\\D     0      1      2      3 \n",
      "     0 1568.78 201.19 159.37 159.12 \n",
      "     1 158.93 1586.29 159.18 159.29 \n",
      "     2 158.97 159.62 1589.52 201.19 \n",
      "     3 159.51 158.86 158.77 1587.91 \n",
      "Bidirectional P2P=Disabled Bandwidth Matrix (GB/s)\n",
      "   D\\D     0      1      2      3 \n",
      "     0 1586.29   9.04  10.18  10.77 \n",
      "     1  11.91 1508.20  11.22  10.54 \n",
      "     2  12.27  10.43 1487.39   9.57 \n",
      "     3  10.49  10.55  10.06 1488.80 \n",
      "Bidirectional P2P=Enabled Bandwidth Matrix (GB/s)\n",
      "   D\\D     0      1      2      3 \n",
      "     0 1585.49 518.97 501.18 506.62 \n",
      "     1 517.97 1581.48 477.50 507.80 \n",
      "     2 339.77 269.55 1586.29 389.30 \n",
      "     3 324.14 363.31 312.47 1587.10 \n",
      "P2P=Disabled Latency Matrix (us)\n",
      "   GPU     0      1      2      3 \n",
      "     0   2.38  24.56  26.20  28.22 \n",
      "     1  29.80   2.29  24.41  36.99 \n",
      "     2  24.32  25.40   2.29  24.39 \n",
      "     3  78.45  26.06  26.53   2.37 \n",
      "\n",
      "   CPU     0      1      2      3 \n",
      "     0   3.89   9.55   9.45   9.96 \n",
      "     1   9.73   3.23   9.77   9.77 \n",
      "     2   9.24   9.92   3.19  10.00 \n",
      "     3   9.84   9.65   9.90   3.15 \n",
      "P2P=Enabled Latency (P2P Writes) Matrix (us)\n",
      "   GPU     0      1      2      3 \n",
      "     0   2.38   2.95   3.02   2.96 \n",
      "     1   2.96   2.29   3.77   3.05 \n",
      "     2   2.96   3.02   2.29   4.00 \n",
      "     3   3.02   3.06   2.95   2.36 \n",
      "\n",
      "   CPU     0      1      2      3 \n",
      "     0   3.26   2.49   2.56   2.54 \n",
      "     1   2.63   3.24   2.58   2.60 \n",
      "     2   2.80   2.60   3.27   2.56 \n",
      "     3   2.66   3.08   3.09   3.24 \n",
      "\n",
      "NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.\n",
      "[P2P (Peer-to-Peer) GPU Bandwidth Latency Test]\n",
      "Device: 0, NVIDIA A100-SXM4-80GB, pciBusID: 7, pciDeviceID: 0, pciDomainID:0\n",
      "Device: 1, NVIDIA A100-SXM4-80GB, pciBusID: f, pciDeviceID: 0, pciDomainID:0\n",
      "Device: 2, NVIDIA A100-SXM4-80GB, pciBusID: 47, pciDeviceID: 0, pciDomainID:0\n",
      "Device: 3, NVIDIA A100-SXM4-80GB, pciBusID: 4e, pciDeviceID: 0, pciDomainID:0\n",
      "Device=0 CAN Access Peer Device=1\n",
      "Device=0 CAN Access Peer Device=2\n",
      "Device=0 CAN Access Peer Device=3\n",
      "Device=1 CAN Access Peer Device=0\n",
      "Device=1 CAN Access Peer Device=2\n",
      "Device=1 CAN Access Peer Device=3\n",
      "Device=2 CAN Access Peer Device=0\n",
      "Device=2 CAN Access Peer Device=1\n",
      "Device=2 CAN Access Peer Device=3\n",
      "Device=3 CAN Access Peer Device=0\n",
      "Device=3 CAN Access Peer Device=1\n",
      "Device=3 CAN Access Peer Device=2\n",
      "\n",
      "***NOTE: In case a device doesn't have P2P access to other one, it falls back to normal memcopy procedure.\n",
      "So you can see lesser Bandwidth (GB/s) and unstable Latency (us) in those cases.\n",
      "\n",
      "P2P Connectivity Matrix\n",
      "     D\\D     0     1     2     3\n",
      "     0\t     1     1     1     1\n",
      "     1\t     1     1     1     1\n",
      "     2\t     1     1     1     1\n",
      "     3\t     1     1     1     1\n",
      "Unidirectional P2P=Disabled Bandwidth Matrix (GB/s)\n",
      "   D\\D     0      1      2      3 \n",
      "     0 1570.35   8.19   9.19   8.85 \n",
      "     1   8.25 1553.18   9.02   9.17 \n",
      "     2   8.93   9.13 1562.50   8.32 \n",
      "     3   9.10   9.07   8.11 1575.10 \n",
      "Unidirectional P2P=Enabled Bandwidth (P2P Writes) Matrix (GB/s)\n",
      "   D\\D     0      1      2      3 \n",
      "     0 1571.93 174.37 148.05 146.02 \n",
      "     1 145.73 1579.88 157.92 146.02 \n",
      "     2 145.68 145.52 1565.63 175.99 \n",
      "     3 146.14 145.69 145.52 1576.69 \n",
      "Bidirectional P2P=Disabled Bandwidth Matrix (GB/s)\n",
      "   D\\D     0      1      2      3 \n",
      "     0 1580.68   8.91   9.98   9.90 \n",
      "     1   9.46 1500.96  10.35   9.07 \n",
      "     2  11.29  10.95 1464.39   8.54 \n",
      "     3  12.94  10.33  12.17 1587.91 \n",
      "Bidirectional P2P=Enabled Bandwidth Matrix (GB/s)\n",
      "   D\\D     0      1      2      3 \n",
      "     0 1578.28 341.44 316.75 385.74 \n",
      "     1 321.03 1592.76 360.17 325.29 \n",
      "     2 480.38 514.73 1586.29 514.40 \n",
      "     3 516.78 515.58 501.35 1587.91 \n",
      "P2P=Disabled Latency Matrix (us)\n",
      "   GPU     0      1      2      3 \n",
      "     0   2.60  26.37  26.40  24.82 \n",
      "     1  24.43   2.34  24.11  24.38 \n",
      "     2  24.17  24.23   2.36  24.33 \n",
      "     3  24.11  24.46  24.49   2.28 \n",
      "\n",
      "   CPU     0      1      2      3 \n",
      "     0   3.22   9.64   9.33   9.33 \n",
      "     1   9.50   3.13   9.35   9.26 \n",
      "     2   9.20   9.26   3.14   9.24 \n",
      "     3   9.21   9.17   9.03   3.14 \n",
      "P2P=Enabled Latency (P2P Writes) Matrix (us)\n",
      "   GPU     0      1      2      3 \n",
      "     0   2.62   3.02   2.97   3.03 \n",
      "     1   3.05   2.34   2.96   3.03 \n",
      "     2   3.01   3.04   2.34   2.96 \n",
      "     3   2.99   3.00   2.96   2.28 \n",
      "\n",
      "   CPU     0      1      2      3 \n",
      "     0   3.23   2.53   2.56   2.57 \n",
      "     1   2.64   3.29   2.59   2.54 \n",
      "     2   2.81   2.57   3.24   3.15 \n",
      "     3   2.70   2.60   3.23   3.23 \n",
      "\n",
      "NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.\n"
     ]
    }
   ],
   "source": [
    "COMMAND = SINGULARITY_RUN + ' ./p2pBandwidthLatencyTest 2> /dev/null'\n",
    "!echo $COMMAND > command && srun --partition=gpu -n2 --gres=gpu:4 /bin/bash ./command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cec4a3",
   "metadata": {},
   "source": [
    "The first part of the benchmark gives device information and P2P access available from each GPU (similar to `nvidia-smi topo -m` command). Next, the benchmark measures the unidirectional and bidirectional bandwidth and latency with P2P disabled and enabled.\n",
    "\n",
    "We share partial results obtained on running the command on DGX-1 : :\n",
    "\n",
    "```bash\n",
    "Bidirectional P2P=Disabled Bandwidth Matrix (GB/s)\n",
    "   D\\D     0      1      2      3      4      5      6      7 \n",
    "     0 783.95   9.56  14.43  14.46  14.47  14.24  14.51  14.43 \n",
    "\n",
    "Bidirectional P2P=Enabled Bandwidth Matrix (GB/s)\n",
    "   D\\D     0      1      2      3      4      5      6      7 \n",
    "     0 784.87  48.49  48.49  96.85  96.90  14.25  14.54  14.49 \n",
    "     \n",
    "P2P=Disabled Latency Matrix (us)\n",
    "   GPU     0      1      2      3      4      5      6      7 \n",
    "     0   1.78  17.52  16.41  16.43  17.35  16.88  17.34  16.85 \n",
    "     \n",
    "P2P=Enabled Latency (P2P Writes) Matrix (us)\n",
    "   GPU     0      1      2      3      4      5      6      7 \n",
    "     0   1.76   1.62   1.61   2.01   2.02  18.44  19.15  19.34\n",
    "```\n",
    "\n",
    "Our system is based on PCIe gen 3.0 with a peak maximum GPU-GPU PCIe banwidth of 15.75 GB/s. Let us analyze and understand these results:\n",
    "\n",
    "* GPU 0 and GPU 1/2: Connected by a single NVLink connection. By enabling P2P-\n",
    "  - Bandwidth reaches close to the maximum peak of 50 GB/s.\n",
    "  - Latency decreases by an order of magnitude.\n",
    "* GPU 0 and GPU 3/4: Connected by a double NVLink connection. By enabling P2P-\n",
    "  - Bandwidth reaches close to the maximum peak of 100 GB/s.\n",
    "  - Latency decreases by an order of magnitude.\n",
    "* GPU 0 and GPU 5/6/7: Connected by PCIe and SMP interconnect. By enabling P2P- \n",
    "  - Bandwidth is unchanged.\n",
    "  - Latency increases marginally.\n",
    "  \n",
    "Correlate these results with the communication topology that can be displayed by usng `nvidia-smi topo -m` command and the qualtitative table in the previous section. They should be consistent with one another.\n",
    "\n",
    "In general, we should try to set the GPUs in an application such that a GPU can share data with its neighbours using a high-bandwidth, low-latency communication topology. Enabling P2P, when possible, usually improves the performance by eliminating host staging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6305bd4c",
   "metadata": {},
   "source": [
    "**Now that we understand the role of system topology in distributed deep learning , let us now get hands-on with refractoring and scaling Deep learning models in the upcoming notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e57415",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Licensing\n",
    "\n",
    "This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200bbfb9-9036-46e2-8f5d-c83be119ba68",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <span style=\"float: left; width: 33%; text-align: left;\"><a href=\"1.Introduction-to-Distributed-Deep-Learning.ipynb\">Previous Notebook</a></span>\n",
    "    <span style=\"float: left; width: 33%; text-align: center;\">\n",
    "        <a href=\"1.Introduction-to-Distributed-Deep-Learning.ipynb\">1</a>\n",
    "        <a >2</a>\n",
    "        <a href=\"3.Hands-on-Multi-GPU.ipynb\">3</a>\n",
    "        <a href=\"4.Convergence.ipynb\">4</a>\n",
    "    </span>\n",
    "    <span style=\"float: left; width: 33%; text-align: right;\"><a href=\"3.Hands-on-Multi-GPU.ipynb\">Next Notebook</a></span>\n",
    "</div>\n",
    "\n",
    "<p> <center> <a href=\"../Start_Here.ipynb\">Home Page</a> </center> </p>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
